{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061b42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30854d31",
   "metadata": {},
   "source": [
    "# facts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89b38099",
   "metadata": {},
   "source": [
    ".compute() --> get result \n",
    ".persist() --> generates “Futures” , keep result in memory, Analyses on this persisted data is faster\n",
    "## sorting is hard to do in parallel\n",
    "## set_index maybe slower\n",
    "map_partitions: run a function at each partition\n",
    "## meta can determine the actual output structure\n",
    "??? meta add multiple names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(\"2021-09-01\", periods=12400, freq=\"1H\")\n",
    "df = pd.DataFrame({\"a\": np.arange(12400), \"b\": list(\"abcaddbe\" * 1550)}, index=index)\n",
    "ddf = dd.from_pandas(df, npartitions=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abfb85",
   "metadata": {},
   "source": [
    "# ex01 example of map_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_converter(df, multiplier=1): \n",
    "    return df['a'] * multiplier\n",
    "meta = pd.Series(name=\"multi\", dtype=\"float64\")\n",
    "distance_km = ddf.map_partitions(\n",
    "    my_custom_converter, multiplier=2, meta=meta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = distance_km.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17054c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5247433",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_km.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f84fa",
   "metadata": {},
   "source": [
    "# Ex02 dask delay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def inc(x):\n",
    "   return x + 1\n",
    "\n",
    "@dask.delayed\n",
    "def add(x, y):\n",
    "   return x + y\n",
    "a = inc(1)       # no work has happened yet\n",
    "b = inc(2)       # no work has happened yet\n",
    "c = add(a, b)    # no work has happened yet\n",
    "c = c.compute()  # This triggers all of the above computations\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4fc59",
   "metadata": {},
   "source": [
    "# Ex03 Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.shutdown()\n",
    "#client.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7756eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=10)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c034323",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728f8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eda2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eafc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (ddf.a.cumsum() - 100).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504bed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4d86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c050067d",
   "metadata": {},
   "source": [
    "# Ex04 Paralleize a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "def inc(x):\n",
    "    sleep(0.01)\n",
    "    return x + 1\n",
    "def add(x):\n",
    "    sleep(0.1)\n",
    "    return x + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49912933",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_list = []\n",
    "for i in range(1, 100):\n",
    "    my_list.append(i)\n",
    "results = []\n",
    "for x in my_list:\n",
    "    y = inc(x)\n",
    "    z = add(y)\n",
    "    results.append(z)\n",
    "total = sum(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dask import delayed\n",
    "results = []\n",
    "for x in my_list:\n",
    "    y = delayed(inc)(x)\n",
    "    z = delayed(add)(y)\n",
    "    results.append(z)\n",
    "total = delayed(sum)(results)\n",
    "#total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3c0e9",
   "metadata": {},
   "source": [
    "# Ex06  A Typical Workflow for dask delay\n",
    "# to delay or not to delay ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e92f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "data_path = r'Z:\\vclgp\\xiongl\\ProjectIS2CalVal\\result\\*\\*\\rh*.parquet'\n",
    "file_list = glob.glob(data_path) # , recursive=True\n",
    "file_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c15e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "ddf_rh = dd.read_parquet(file_list[:100])\n",
    "ddf_rh.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52889f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import pandas as pd\n",
    "\n",
    "@dask.delayed\n",
    "def process_file(filename):\n",
    "    data = pd.read_parquet(filename)\n",
    "    return data\n",
    "results = []\n",
    "for filename in file_list:\n",
    "    results.append(process_file(filename))\n",
    "res = dask.compute(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bf6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat(res[0], ignore_index=True)\n",
    "#res_df  = pd.DataFrame(res[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9b436",
   "metadata": {},
   "source": [
    "# EX07 dask distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9269d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cores and Logical Processors (Threads)\n",
    "# my laptop:\n",
    "#Processor\t12th Gen Intel(R) Core(TM) i9-12900H, 2500 Mhz, 14 Core(s), 20 Logical Processor(s)\n",
    "from dask.distributed import LocalCluster, Client\n",
    "cluster = LocalCluster()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8aaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfacd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "42c9531f",
   "metadata": {},
   "source": [
    "# Nanny process being referenced from time to time. This is a wrapper for the worker that handles restarting the process if it is killed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f745b2b",
   "metadata": {},
   "source": [
    "# EX08 futures: real-time execution for custom situations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6adf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    data = pd.read_parquet(filename)\n",
    "    return data\n",
    "futures = []\n",
    "for filename in file_list[:500]:\n",
    "    future = client.submit(process_file, filename)\n",
    "    futures.append(future)\n",
    "from dask.distributed import wait, progress\n",
    "#future = client.submit(process_file, file_list[1])\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09e58a",
   "metadata": {},
   "source": [
    "You can block on the computation and gather the result with the .result() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f855808",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e6a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af18e154",
   "metadata": {},
   "source": [
    "# EX09 difference between delayed and future\n",
    "future: call returns immediately;\n",
    "\n",
    "whose status begins as “pending” and later becomes “finished”\n",
    "\n",
    "as soon as the inputs are available and there is compute available, the computation starts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00f9e8",
   "metadata": {},
   "source": [
    "<!-- # wait(future)\n",
    "# client.gather(futures) # we normally don’t want to gather() results that are too big in memory.\n",
    "# future_z = client.submit(sum, [future_x, future_y])\n",
    "# number of retries in the client.compute, client.submit or client.map method.\n",
    "# can be passed to new tasks without having to pull data locally from the cluster -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of retries in the client.compute, client.submit or client.map method.\n",
    "# can be passed to new tasks without having to pull data locally from the cluster"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a62b0c3",
   "metadata": {},
   "source": [
    "# Avoid calling compute repeatedly\n",
    "# If you need to work with large Python objects, then please let Dask create them\n",
    "# Don't\n",
    "ddf = ... a dask dataframe ...\n",
    "for fn in filenames:\n",
    "    df = pandas.read_csv(fn)  # Read locally with pandas\n",
    "    ddf = ddf.append(df)            # Give to Dask\n",
    "# Do \n",
    "ddf = dd.read_csv(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fac7a1",
   "metadata": {},
   "source": [
    "## Repartition to Reduce Overhead"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fd85d52",
   "metadata": {},
   "source": [
    "\n",
    "df = dd.read_csv('s3://bucket/path/to/*.csv')\n",
    "df = df[df.name == 'Alice']  # only 1/100th of the data\n",
    "df = df.repartition(npartitions=df.npartitions // 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9cb4f",
   "metadata": {},
   "source": [
    "# using the .set_index(column_name) method is expensive !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a2c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
